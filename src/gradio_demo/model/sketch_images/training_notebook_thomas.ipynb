{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a31e4fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/ml-deploy/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device is: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from gradio_demo.model.utils import output_conv_size\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Current device is: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ad190b",
   "metadata": {},
   "source": [
    "Loading the dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67112611",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Xenova/quickdraw-small\")\n",
    "\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize((0,), (1,))\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess_ops(examples):\n",
    "    examples[\"image\"] = [preprocess(image) for image in examples[\"image\"]]\n",
    "    return examples\n",
    "\n",
    "\n",
    "dataset.set_transform(preprocess_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e982d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of trainset: 1500000, testset: 250000\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset, val_dataset = (\n",
    "    dataset[\"train\"],\n",
    "    dataset[\"test\"],\n",
    "    dataset[\"valid\"],\n",
    ")\n",
    "train_dataset = train_dataset.shard(num_shards=3, index=0)\n",
    "names = train_dataset.features[\"label\"].names\n",
    "n_classes = len(names)\n",
    "print(f\"size of trainset: {len(train_dataset)}, testset: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d013cd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x79b19c2dfcb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"labels.json\", \"w\") as f:\n",
    "    json.dump(names, f)\n",
    "\n",
    "\n",
    "def id_to_class(idx):\n",
    "    return names[idx]\n",
    "\n",
    "\n",
    "# visualizing an example\n",
    "idx = torch.randint(0, 100, (1,))\n",
    "img, label = test_dataset[idx][\"image\"], test_dataset[idx][\"label\"]\n",
    "img = img[0].squeeze(dim=0)\n",
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8694f9a2",
   "metadata": {},
   "source": [
    "Model architechture\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743f9359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device is: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Current device is: {device}\")\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_filters, hidden_dim, n_layers, n_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, n_filters, 3, padding =1),\n",
    "            nn.BatchNorm2d(n_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(n_filters, 2 * n_filters, 3, padding = 1),\n",
    "            nn.BatchNorm2d(2 * n_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(2*n_filters, 4*n_filters, 3, padding=1),\n",
    "            nn.BatchNorm2d(4*n_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "\n",
    "        # self.conv1 = nn.Conv2d(1, n_filters, conv_kernel_size)\n",
    "        # self.relu1 = nn.ReLU()\n",
    "        # self.maxpool1 = nn.MaxPool2d(maxpool_kernel_size)\n",
    "        # self.conv2 = nn.Conv2d(n_filters, 2*n_filters, conv_kernel_size)\n",
    "        # self.relu2 = nn.ReLU()\n",
    "        # self.maxpool2 = nn.MaxPool2d(maxpool_kernel_size)\n",
    "        # self.input_dim = output_conv_size(img.shape[0], img.shape[1],conv_kernel_size=conv_kernel_size,maxpool_kernel_size=maxpool_kernel_size,n_filters=n_filters)#960\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.input_dim = 1080# 2940#1500 # 960\n",
    "        self.inp_layer = nn.Linear(self.input_dim, hidden_dim)\n",
    "        self.classifier = nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_dim, hidden_dim),\n",
    "                    nn.BatchNorm1d(hidden_dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(p=0.5),\n",
    "                )\n",
    "                for i in range(n_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.out_layer = nn.Linear(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.inp_layer(torch.flatten(x, start_dim=1))\n",
    "        for layer in self.classifier:\n",
    "            x = layer(x)\n",
    "        x = self.out_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cb51eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params 579909\n"
     ]
    }
   ],
   "source": [
    "params = {\"n_filters\": 30, \"hidden_dim\": 256, \"n_layers\": 2, \"n_classes\": n_classes}\n",
    "model = CNN(**params).to(device)\n",
    "n_params = sum([p.numel() for p in model.parameters()])\n",
    "print(f\"Number of params {n_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f11b91b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/ml-deploy/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "lr = 1e-3\n",
    "batch_size = 512\n",
    "n_epochs = 6\n",
    "num_workers = 40\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay = 1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "trainLoader, testLoader = (\n",
    "    DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers),\n",
    "    DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1ee08a",
   "metadata": {},
   "source": [
    "Training loop\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d81dc224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(model, trainLoader, testLoader, criterion, optimizer, n_epochs, device):\n",
    "#     train_losses = []\n",
    "#     train_accs = []\n",
    "#     test_losses = []\n",
    "#     test_accs = []\n",
    "#     for epoch in range(1, n_epochs + 1):\n",
    "#         model.train()\n",
    "#         train_loss = 0\n",
    "#         train_acc = 0\n",
    "#         for batch in tqdm(trainLoader):\n",
    "#             data, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "#             out = model(data)\n",
    "#             preds = out.argmax(dim=1)\n",
    "#             loss = criterion(out, labels)\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             train_loss += loss.item()\n",
    "#             train_acc += (preds == labels).sum().item()\n",
    "\n",
    "#         train_loss /= len(trainLoader)\n",
    "#         train_acc /= len(trainLoader.dataset)\n",
    "#         train_accs.append(train_acc)\n",
    "#         train_losses.append(train_loss)\n",
    "\n",
    "#         model.eval()\n",
    "#         test_loss = 0\n",
    "#         test_acc = 0\n",
    "#         with torch.no_grad():\n",
    "#             for batch in tqdm(testLoader, disable=True):\n",
    "#                 data, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "#                 out = model(data)\n",
    "#                 loss = criterion(out, labels)\n",
    "#                 preds = out.argmax(dim=1)\n",
    "#                 test_loss += loss.item()\n",
    "#                 test_acc += (preds == labels).sum().item()\n",
    "\n",
    "#         test_loss /= len(testLoader)\n",
    "#         test_acc /= len(testLoader.dataset)\n",
    "#         test_accs.append(test_acc)\n",
    "#         test_losses.append(test_loss)\n",
    "\n",
    "#         print(\n",
    "#             f\"epoch {epoch} | train loss {train_loss:.3f} train acc {train_acc:.2f} | test loss {test_loss:.3f} test acc {test_acc:.2f}\"\n",
    "#         )\n",
    "#     return train_losses, train_accs, test_losses, test_accs\n",
    "\n",
    "\n",
    "def train(model, trainLoader, testLoader, criterion, optimizer, n_epochs, device):\n",
    "    train_losses, train_accs, test_losses, test_accs = [], [], [], []\n",
    "    \n",
    "    # epoch_bar = tqdm(range(1, n_epochs + 1), desc=\"Overall Training\", leave=True)\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # -------------------------\n",
    "        # ðŸ”¹ TRAINING PHASE\n",
    "        # -------------------------\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        progress = tqdm(trainLoader, desc=f\"Epoch {epoch}/{n_epochs}\", leave=False)\n",
    "\n",
    "        for batch in progress:\n",
    "            data, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "            out = model(data)\n",
    "            loss = criterion(out, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            preds = out.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # update tqdm bar\n",
    "            progress.set_postfix({\n",
    "                \"train_loss\": f\"{running_loss / (total / labels.size(0)):.4f}\",\n",
    "                \"train_acc\": f\"{correct / total:.3f}\"\n",
    "            })\n",
    "\n",
    "        # compute final training stats for the epoch\n",
    "        train_loss = running_loss / len(trainLoader)\n",
    "        train_acc = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        # -------------------------\n",
    "        # ðŸ”¹ VALIDATION PHASE\n",
    "        # -------------------------\n",
    "        model.eval()\n",
    "        test_loss, test_correct, test_total = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in testLoader:\n",
    "                data, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "                out = model(data)\n",
    "                loss = criterion(out, labels)\n",
    "\n",
    "                preds = out.argmax(dim=1)\n",
    "                test_correct += (preds == labels).sum().item()\n",
    "                test_total += labels.size(0)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        test_loss /= len(testLoader)\n",
    "        test_acc = test_correct / test_total\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "\n",
    "        # -------------------------\n",
    "        # ðŸ”¹ SUMMARY PRINT\n",
    "        # -------------------------\n",
    "        print(f\"âœ… Epoch {epoch}/{n_epochs} completed | \"\n",
    "              f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.3f} | \"\n",
    "              f\"Test Loss: {test_loss:.4f} Acc: {test_acc:.3f}\")\n",
    "\n",
    "    return train_losses, train_accs, test_losses, test_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12ad96a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 1/6 completed | Train Loss: 2.8716 Acc: 0.356 | Test Loss: 1.9950 Acc: 0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 2/6 completed | Train Loss: 2.3304 Acc: 0.458 | Test Loss: 1.8038 Acc: 0.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 3/6 completed | Train Loss: 2.2149 Acc: 0.482 | Test Loss: 1.7546 Acc: 0.584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 4/6 completed | Train Loss: 2.1482 Acc: 0.497 | Test Loss: 1.7046 Acc: 0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 5/6 completed | Train Loss: 2.1033 Acc: 0.507 | Test Loss: 1.6695 Acc: 0.600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 6/6 completed | Train Loss: 2.0703 Acc: 0.514 | Test Loss: 1.6425 Acc: 0.607\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_accs, test_losses, test_accs = train(\n",
    "    model, trainLoader, testLoader, criterion, optimizer, n_epochs, device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "969b1ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'weights/cnn_3_conv.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradio-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
