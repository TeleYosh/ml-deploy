{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a31e4fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/ml-deploy/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device is: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "import random\n",
    "# from gradio_demo.model.utils import output_conv_size\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Current device is: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ad190b",
   "metadata": {},
   "source": [
    "Loading the dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a71f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Xenova/quickdraw-small\")\n",
    "\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize((0,), (1,))\n",
    "    ]\n",
    ")\n",
    "\n",
    "def preprocess_ops(examples):\n",
    "    examples[\"image\"] = [preprocess(image) for image in examples[\"image\"]]\n",
    "    return examples\n",
    "\n",
    "dataset.set_transform(preprocess_ops)\n",
    "\n",
    "train_dataset, test_dataset, val_dataset = (\n",
    "    dataset[\"train\"],\n",
    "    dataset[\"test\"],\n",
    "    dataset[\"valid\"],\n",
    ")\n",
    "# train_dataset = train_dataset.shard(num_shards=3, index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5879241d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726fe5e1",
   "metadata": {},
   "source": [
    "#### With data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67112611",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Xenova/quickdraw-small\")\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)), \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Validation/Test: No random changes, just format\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def preprocess_train(examples):\n",
    "    # Apply the \"noisy\" transforms to the list of images\n",
    "    examples[\"image\"] = [train_transforms(image) for image in examples[\"image\"]]\n",
    "    return examples\n",
    "\n",
    "def preprocess_eval(examples):\n",
    "    # Apply the \"clean\" transforms\n",
    "    examples[\"image\"] = [eval_transforms(image) for image in examples[\"image\"]]\n",
    "    return examples\n",
    "\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset  = dataset[\"test\"]\n",
    "val_dataset   = dataset[\"valid\"]\n",
    "\n",
    "train_dataset = train_dataset.shard(num_shards=3, index=0)\n",
    "\n",
    "# 6. Apply the transforms to the specific splits\n",
    "train_dataset.set_transform(preprocess_train)\n",
    "test_dataset.set_transform(preprocess_eval)\n",
    "val_dataset.set_transform(preprocess_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12887ec0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e982d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of trainset: 4500000, testset: 250000\n"
     ]
    }
   ],
   "source": [
    "names = train_dataset.features[\"label\"].names\n",
    "n_classes = len(names)\n",
    "print(f\"size of trainset: {len(train_dataset)}, testset: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d013cd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7dd4b9f66270>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHANJREFUeJzt3X9sVfX9x/FXKe0Fpb211Pb2SgsFFRYRzBC6Tu1QGkpdjCBZ0PkHGoODFTNl6tJlirIl3ViyGU2n+8PBzMRfyYBoNhastsytYEAJw7mGNtWW0R/C1nuh0NK1n+8ffL3bFUo9l3v7bm+fj+ST0HPOu+fNx+N9ce49/TTFOecEAMAIm2DdAABgfCKAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYGKidQNfNDg4qGPHjikjI0MpKSnW7QAAPHLO6eTJkwoGg5owYej7nFEXQMeOHVNBQYF1GwCAS9TW1qZp06YNuX/UvQWXkZFh3QIAIA6Gez1PWADV1NRoxowZmjRpkoqLi/X+++9/qTredgOA5DDc63lCAui1117Thg0btHHjRn3wwQeaP3++ysvL1dXVlYjTAQDGIpcAixYtcpWVlZGvBwYGXDAYdNXV1cPWhkIhJ4nBYDAYY3yEQqGLvt7H/Q7o7NmzOnDggMrKyiLbJkyYoLKyMjU0NJx3fF9fn8LhcNQAACS/uAfQ8ePHNTAwoLy8vKjteXl56ujoOO/46upq+f3+yOAJOAAYH8yfgquqqlIoFIqMtrY265YAACMg7j8HlJOTo9TUVHV2dkZt7+zsVCAQOO94n88nn88X7zYAAKNc3O+A0tPTtWDBAtXW1ka2DQ4Oqra2ViUlJfE+HQBgjErISggbNmzQ6tWrdeONN2rRokV65pln1NPTo/vvvz8RpwMAjEEJCaBVq1bps88+05NPPqmOjg7dcMMN2rVr13kPJgAAxq8U55yzbuJ/hcNh+f1+6zYAAJcoFAopMzNzyP3mT8EBAMYnAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYmWjcQL1OnTvVc88ADD8R0rjlz5niumT17tueaQCDguSYZpaene67JzMyM6VzHjx/3XBMKhTzXtLe3e67p6uryXNPR0eG5RpI6Ozs915w6dcpzzcSJ3l+C/vznP3uuiWXuJOmzzz6LqQ5fDndAAAATBBAAwETcA+ipp55SSkpK1IjlLSsAQHJLyGdA1113nd5+++3/niSG93kBAMktIckwceJEPkAHAFxUQj4DOnLkiILBoGbOnKl7771Xra2tQx7b19encDgcNQAAyS/uAVRcXKytW7dq165dev7559XS0qJbbrlFJ0+evODx1dXV8vv9kVFQUBDvlgAAo1DcA6iiokLf+ta3NG/ePJWXl+sPf/iDuru79frrr1/w+KqqKoVCochoa2uLd0sAgFEo4U8HZGVl6dprr1VTU9MF9/t8Pvl8vkS3AQAYZRL+c0CnTp1Sc3Oz8vPzE30qAMAYEvcAevTRR1VfX69PPvlEf/3rX7VixQqlpqbqnnvuifepAABjWNzfgjt69KjuuecenThxQldeeaVuvvlm7d27V1deeWW8TwUAGMNSnHPOuon/FQ6H5ff7Pdfdf//9nmt+85vfeK6RFNODEh9//LHnmos9vj6UwcFBzzWj3Q033OC5ZuHChTGd68UXX/RcE8tCuLH8gywvL89zTaxvfU+ZMiWmumTT39/vuSaWBUyPHTvmuWbdunWeayRp//79MdXFIhQKXXRhYNaCAwCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYCLhv5BupHz00Ucjdq7vfOc7nmv++Mc/JqCT8aGmpsZzTTAYjOlca9asiaku2Vx22WWea5577jnPNStWrPBcE8vCw7EuyhrLArA5OTmea2J5Tbn99ts910gjuxjpcLgDAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYSJrVsA8dOuS5pr+/P6Zz3XjjjZ5rWA07doWFhZ5rjh49moBOxo/Tp097rklNTfVc09XV5blm586dnmtGu1hWtp4+fXoCOhlZ3AEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwkTSLkfb29nqu+fTTT2M614wZM2KqQ2wKCgo81zQ2NiagE1zMFVdc4bmmu7s7/o2MQZ988onnmmR4HeIOCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgImkWYw0FuFwOKa6zMzMOHeCiyksLPRcs3v37gR0govJysryXPPvf/87/o2MQbEsjFxaWpqATkYWd0AAABMEEADAhOcA2rNnj+644w4Fg0GlpKRox44dUfudc3ryySeVn5+vyZMnq6ysTEeOHIlXvwCAJOE5gHp6ejR//nzV1NRccP/mzZv17LPP6oUXXtC+fft0+eWXq7y8PKZfGAcASF6eH0KoqKhQRUXFBfc55/TMM8/oRz/6ke68805J0ksvvaS8vDzt2LFDd99996V1CwBIGnH9DKilpUUdHR0qKyuLbPP7/SouLlZDQ8MFa/r6+hQOh6MGACD5xTWAOjo6JEl5eXlR2/Py8iL7vqi6ulp+vz8yCgoK4tkSAGCUMn8KrqqqSqFQKDLa2tqsWwIAjIC4BlAgEJAkdXZ2Rm3v7OyM7Psin8+nzMzMqAEASH5xDaCioiIFAgHV1tZGtoXDYe3bt08lJSXxPBUAYIzz/BTcqVOn1NTUFPm6paVFBw8eVHZ2tgoLC/Xwww/rJz/5ia655hoVFRXpiSeeUDAY1PLly+PZNwBgjPMcQPv379ett94a+XrDhg2SpNWrV2vr1q16/PHH1dPTowcffFDd3d26+eabtWvXLk2aNCl+XQMAxjzPAbR48WI554bcn5KSok2bNmnTpk2X1NhIYDHSkTdlyhTPNVdccYXnGh5mGXmx/Hf65z//mYBOxp5YFiONZZFeSUpNTfVcMzAwENO5hmP+FBwAYHwigAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJjwvBp2MgmFQjHV5eXlxbmT8WOkfi8Uq2GPvFhWw+7u7o5/I2PQJ5984rkmLS0tpnPl5+d7rjl69GhM5xoOd0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMjOvFSMPhcEx111xzTZw7GT9WrVo1IudpbW0dkfPgv3Jzcz3XBIPBBHQy9nz66acjdq4ZM2Z4rmExUgBAUiGAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGBiXC9GOjAwEFNdWlpanDsZP0Zq7tra2kbkPMlq4kTvLw3p6emea/Lz8z3XJKOWlpYRO1csi5G+99578W9E3AEBAIwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwMa4XI500aVJMdb29vXHuZPz46KOPPNfcdtttnmu6uro81+C//vOf/3iuCYfDnmuampo81ySjzz77bMTONXXq1BE713C4AwIAmCCAAAAmPAfQnj17dMcddygYDColJUU7duyI2n/fffcpJSUlaixbtixe/QIAkoTnAOrp6dH8+fNVU1Mz5DHLli1Te3t7ZLzyyiuX1CQAIPl4fgihoqJCFRUVFz3G5/MpEAjE3BQAIPkl5DOguro65ebmavbs2Vq3bp1OnDgx5LF9fX0Kh8NRAwCQ/OIeQMuWLdNLL72k2tpa/exnP1N9fb0qKio0MDBwweOrq6vl9/sjo6CgIN4tAQBGobj/HNDdd98d+fP111+vefPmadasWaqrq9OSJUvOO76qqkobNmyIfB0OhwkhABgHEv4Y9syZM5WTkzPkD5z5fD5lZmZGDQBA8kt4AB09elQnTpxQfn5+ok8FABhDPL8Fd+rUqai7mZaWFh08eFDZ2dnKzs7W008/rZUrVyoQCKi5uVmPP/64rr76apWXl8e1cQDA2OY5gPbv369bb7018vXnn9+sXr1azz//vA4dOqTf/va36u7uVjAY1NKlS/XjH/9YPp8vfl0DAMY8zwG0ePFiOeeG3P+nP/3pkhoaSZMnT46p7syZM3HuZPyIZZHQiRO9PyuTmprquUbSkE9rYnix/H9x/PjxBHSCi0lJSbFuIYK14AAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJuL+K7nHElbDHnn/+te/PNcMDg56rollBW2J1bAvRVpamueas2fPJqATjBXcAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDBYqQx6OnpiXMn48dLL73kuaahocFzTV9fn+ca/Nf06dM912RlZXmu8fl8nmuQPLgDAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYGJcL0Y6adKkmOpOnDgR507Gj1gWCT18+HACOsHFtLe3e67ZtGmT55qamhrPNUge3AEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwWKkMejt7Y1zJ8DocvbsWc81Tz/9dAI6GR8GBgZGpEaKbUHgROEOCABgggACAJjwFEDV1dVauHChMjIylJubq+XLl6uxsTHqmN7eXlVWVmrq1KmaMmWKVq5cqc7Ozrg2DQAY+zwFUH19vSorK7V3717t3r1b/f39Wrp0qXp6eiLHPPLII3rzzTf1xhtvqL6+XseOHdNdd90V98YBAGObp4cQdu3aFfX11q1blZubqwMHDqi0tFShUEgvvviitm3bpttuu02StGXLFn3lK1/R3r179bWvfS1+nQMAxrRL+gwoFApJkrKzsyVJBw4cUH9/v8rKyiLHzJkzR4WFhWpoaLjg9+jr61M4HI4aAIDkF3MADQ4O6uGHH9ZNN92kuXPnSpI6OjqUnp6urKysqGPz8vLU0dFxwe9TXV0tv98fGQUFBbG2BAAYQ2IOoMrKSh0+fFivvvrqJTVQVVWlUCgUGW1tbZf0/QAAY0NMP4i6fv16vfXWW9qzZ4+mTZsW2R4IBHT27Fl1d3dH3QV1dnYqEAhc8Hv5fD75fL5Y2gAAjGGe7oCcc1q/fr22b9+ud955R0VFRVH7FyxYoLS0NNXW1ka2NTY2qrW1VSUlJfHpGACQFDzdAVVWVmrbtm3auXOnMjIyIp/r+P1+TZ48WX6/Xw888IA2bNig7OxsZWZm6qGHHlJJSQlPwAEAongKoOeff16StHjx4qjtW7Zs0X333SdJ+uUvf6kJEyZo5cqV6uvrU3l5uX71q1/FpVkAQPLwFEDOuWGPmTRpkmpqalRTUxNzUyNl8uTJMdWdOXMmzp0AGM9iWSD061//ekznOnz4cEx1icBacAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEzH9RtRk0dzcHFPd3/72tzh3AgDevP/++9YtXDLugAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJhIcc456yb+Vzgclt/vt24DAHCJQqGQMjMzh9zPHRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE54CqLq6WgsXLlRGRoZyc3O1fPlyNTY2Rh2zePFipaSkRI21a9fGtWkAwNjnKYDq6+tVWVmpvXv3avfu3erv79fSpUvV09MTddyaNWvU3t4eGZs3b45r0wCAsW+il4N37doV9fXWrVuVm5urAwcOqLS0NLL9sssuUyAQiE+HAICkdEmfAYVCIUlSdnZ21PaXX35ZOTk5mjt3rqqqqnT69Okhv0dfX5/C4XDUAACMAy5GAwMD7pvf/Ka76aaborb/+te/drt27XKHDh1yv/vd79xVV13lVqxYMeT32bhxo5PEYDAYjCQboVDoojkScwCtXbvWTZ8+3bW1tV30uNraWifJNTU1XXB/b2+vC4VCkdHW1mY+aQwGg8G49DFcAHn6DOhz69ev11tvvaU9e/Zo2rRpFz22uLhYktTU1KRZs2adt9/n88nn88XSBgBgDPMUQM45PfTQQ9q+fbvq6upUVFQ0bM3BgwclSfn5+TE1CABITp4CqLKyUtu2bdPOnTuVkZGhjo4OSZLf79fkyZPV3Nysbdu26fbbb9fUqVN16NAhPfLIIyotLdW8efMS8hcAAIxRXj730RDv823ZssU551xra6srLS112dnZzufzuauvvto99thjw74P+L9CoZD5+5YMBoPBuPQx3Gt/yv8Hy6gRDofl9/ut2wAAXKJQKKTMzMwh97MWHADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADAxKgLIOecdQsAgDgY7vV81AXQyZMnrVsAAMTBcK/nKW6U3XIMDg7q2LFjysjIUEpKStS+cDisgoICtbW1KTMz06hDe8zDOczDOczDOczDOaNhHpxzOnnypILBoCZMGPo+Z+II9vSlTJgwQdOmTbvoMZmZmeP6Avsc83AO83AO83AO83CO9Tz4/f5hjxl1b8EBAMYHAggAYGJMBZDP59PGjRvl8/msWzHFPJzDPJzDPJzDPJwzluZh1D2EAAAYH8bUHRAAIHkQQAAAEwQQAMAEAQQAMDFmAqimpkYzZszQpEmTVFxcrPfff9+6pRH31FNPKSUlJWrMmTPHuq2E27Nnj+644w4Fg0GlpKRox44dUfudc3ryySeVn5+vyZMnq6ysTEeOHLFpNoGGm4f77rvvvOtj2bJlNs0mSHV1tRYuXKiMjAzl5uZq+fLlamxsjDqmt7dXlZWVmjp1qqZMmaKVK1eqs7PTqOPE+DLzsHjx4vOuh7Vr1xp1fGFjIoBee+01bdiwQRs3btQHH3yg+fPnq7y8XF1dXdatjbjrrrtO7e3tkfHee+9Zt5RwPT09mj9/vmpqai64f/PmzXr22Wf1wgsvaN++fbr88stVXl6u3t7eEe40sYabB0latmxZ1PXxyiuvjGCHiVdfX6/Kykrt3btXu3fvVn9/v5YuXaqenp7IMY888ojefPNNvfHGG6qvr9exY8d01113GXYdf19mHiRpzZo1UdfD5s2bjToeghsDFi1a5CorKyNfDwwMuGAw6Kqrqw27GnkbN2508+fPt27DlCS3ffv2yNeDg4MuEAi4n//855Ft3d3dzufzuVdeecWgw5HxxXlwzrnVq1e7O++806QfK11dXU6Sq6+vd86d+2+flpbm3njjjcgxH3/8sZPkGhoarNpMuC/Og3POfeMb33Df+9737Jr6Ekb9HdDZs2d14MABlZWVRbZNmDBBZWVlamhoMOzMxpEjRxQMBjVz5kzde++9am1ttW7JVEtLizo6OqKuD7/fr+Li4nF5fdTV1Sk3N1ezZ8/WunXrdOLECeuWEioUCkmSsrOzJUkHDhxQf39/1PUwZ84cFRYWJvX18MV5+NzLL7+snJwczZ07V1VVVTp9+rRFe0MadYuRftHx48c1MDCgvLy8qO15eXn6xz/+YdSVjeLiYm3dulWzZ89We3u7nn76ad1yyy06fPiwMjIyrNsz0dHRIUkXvD4+3zdeLFu2THfddZeKiorU3NysH/7wh6qoqFBDQ4NSU1Ot24u7wcFBPfzww7rppps0d+5cSeeuh/T0dGVlZUUdm8zXw4XmQZK+/e1va/r06QoGgzp06JB+8IMfqLGxUb///e8Nu4026gMI/1VRURH587x581RcXKzp06fr9ddf1wMPPGDYGUaDu+++O/Ln66+/XvPmzdOsWbNUV1enJUuWGHaWGJWVlTp8+PC4+Bz0YoaahwcffDDy5+uvv175+flasmSJmpubNWvWrJFu84JG/VtwOTk5Sk1NPe8pls7OTgUCAaOuRoesrCxde+21ampqsm7FzOfXANfH+WbOnKmcnJykvD7Wr1+vt956S++++27Ur28JBAI6e/asuru7o45P1uthqHm4kOLiYkkaVdfDqA+g9PR0LViwQLW1tZFtg4ODqq2tVUlJiWFn9k6dOqXm5mbl5+dbt2KmqKhIgUAg6voIh8Pat2/fuL8+jh49qhMnTiTV9eGc0/r167V9+3a98847Kioqitq/YMECpaWlRV0PjY2Nam1tTarrYbh5uJCDBw9K0ui6HqyfgvgyXn31Vefz+dzWrVvd3//+d/fggw+6rKws19HRYd3aiPr+97/v6urqXEtLi/vLX/7iysrKXE5Ojuvq6rJuLaFOnjzpPvzwQ/fhhx86Se4Xv/iF+/DDD92nn37qnHPupz/9qcvKynI7d+50hw4dcnfeeacrKipyZ86cMe48vi42DydPnnSPPvqoa2hocC0tLe7tt992X/3qV90111zjent7rVuPm3Xr1jm/3+/q6upce3t7ZJw+fTpyzNq1a11hYaF755133P79+11JSYkrKSkx7Dr+hpuHpqYmt2nTJrd//37X0tLidu7c6WbOnOlKS0uNO482JgLIOeeee+45V1hY6NLT092iRYvc3r17rVsacatWrXL5+fkuPT3dXXXVVW7VqlWuqanJuq2Ee/fdd52k88bq1audc+cexX7iiSdcXl6e8/l8bsmSJa6xsdG26QS42DycPn3aLV261F155ZUuLS3NTZ8+3a1Zsybp/pF2ob+/JLdly5bIMWfOnHHf/e533RVXXOEuu+wyt2LFCtfe3m7XdAIMNw+tra2utLTUZWdnO5/P566++mr32GOPuVAoZNv4F/DrGAAAJkb9Z0AAgOREAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADAxP8BaAfhjRkv4k4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"labels.json\", \"w\") as f:\n",
    "    json.dump(names, f)\n",
    "\n",
    "\n",
    "def id_to_class(idx):\n",
    "    return names[idx]\n",
    "\n",
    "\n",
    "# visualizing an example\n",
    "idx = torch.randint(0, 100, (1,))\n",
    "img, label = test_dataset[idx][\"image\"], test_dataset[idx][\"label\"]\n",
    "img = img[0].squeeze(dim=0)\n",
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8694f9a2",
   "metadata": {},
   "source": [
    "Model architecture\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "743f9359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device is: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Current device is: {device}\")\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_filters,\n",
    "        hidden_dim,\n",
    "        n_layers,\n",
    "        n_classes,\n",
    "        input_shape=(1,28,28),#(1, img.shape[0], img.shape[1]),\n",
    "        dropout_rate=0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, n_filters, 3, padding=1),\n",
    "            nn.BatchNorm2d(n_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(n_filters, 2 * n_filters, 3, padding=1),\n",
    "            nn.BatchNorm2d(2 * n_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(2 * n_filters, 4 * n_filters, 3, padding=1),\n",
    "            nn.BatchNorm2d(4 * n_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        # self.conv4 = nn.Sequential(\n",
    "        #     nn.Conv2d(4 * n_filters, 8 * n_filters, 3, padding=1),\n",
    "        #     nn.BatchNorm2d(8 * n_filters),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2),\n",
    "        # )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        dummy_input = torch.zeros(1, *input_shape)\n",
    "        conv_out_size = self._get_flat_size(dummy_input)\n",
    "        # print(conv_out_size)\n",
    "        self.input_dim = conv_out_size # 1080  # 2940#1500 # 960\n",
    "        self.inp_layer = nn.Linear(self.input_dim, hidden_dim)\n",
    "        self.classifier = nn.ModuleList()\n",
    "        for _ in range(n_layers):\n",
    "            self.classifier.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_dim, hidden_dim),\n",
    "                    nn.BatchNorm1d(hidden_dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(p=dropout_rate),\n",
    "                )\n",
    "            )\n",
    "        self.out_layer = nn.Linear(hidden_dim, n_classes)\n",
    "\n",
    "    def _get_flat_size(self, x):\n",
    "        \"\"\"Helper class to get the flat size of the input after convolutions\"\"\"\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        # x = self.conv4(x)\n",
    "        return int(np.prod(x.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        # x = self.conv4(x)\n",
    "        x = self.inp_layer(torch.flatten(x, start_dim=1))\n",
    "        for layer in self.classifier:\n",
    "            x = layer(x)\n",
    "        x = self.out_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed170d8",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "835fa3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, trainLoader, testLoader, criterion, optimizer, n_epochs, device, scheduler):#, patience=5\n",
    "    train_losses, train_accs, test_losses, test_accs = [], [], [], []\n",
    "\n",
    "    # early_stopper = EarlyStopping(patience=patience, min_delta=0.001)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # -------------------------\n",
    "        # üîπ TRAINING PHASE\n",
    "        # -------------------------\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        progress = tqdm(trainLoader, desc=f\"Epoch {epoch}/{n_epochs}\", leave=False)\n",
    "\n",
    "        for batch in progress:\n",
    "            data, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "            out = model(data)\n",
    "            loss = criterion(out, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            preds = out.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # update tqdm bar\n",
    "            progress.set_postfix(\n",
    "                {\n",
    "                    \"train_loss\": f\"{running_loss / (total / labels.size(0)):.4f}\",\n",
    "                    \"train_acc\": f\"{correct / total:.3f}\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # compute final training stats for the epoch\n",
    "        train_loss = running_loss / len(trainLoader)\n",
    "        train_acc = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        # -------------------------\n",
    "        # üîπ VALIDATION PHASE\n",
    "        # -------------------------\n",
    "        model.eval()\n",
    "        test_loss, test_correct, test_total = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in testLoader:\n",
    "                data, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "                out = model(data)\n",
    "                loss = criterion(out, labels)\n",
    "\n",
    "                preds = out.argmax(dim=1)\n",
    "                test_correct += (preds == labels).sum().item()\n",
    "                test_total += labels.size(0)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        test_loss /= len(testLoader)\n",
    "        test_acc = test_correct / test_total\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "\n",
    "        # -------------------------\n",
    "        # üîπ SCHEDULER STEP (Pour StepLR)\n",
    "        # -------------------------\n",
    "        scheduler.step()\n",
    "\n",
    "        # -------------------------\n",
    "        # üîπ SUMMARY PRINT\n",
    "        # -------------------------\n",
    "        print(\n",
    "            f\"‚úÖ Epoch {epoch}/{n_epochs} completed | \"\n",
    "            f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.3f} | \"\n",
    "            f\"Test Loss: {test_loss:.4f} Acc: {test_acc:.3f}\"\n",
    "        )\n",
    "\n",
    "        # -------------------------\n",
    "        # üîπ EARLY STOPPING CHECK\n",
    "        # -------------------------\n",
    "        # early_stopper(test_loss, model)\n",
    "\n",
    "        # if early_stopper.early_stop:\n",
    "        #     print(f\"üõë Early stopping triggered at epoch {epoch}!\")\n",
    "        #     break\n",
    "        # early_stopper.load_best_weights(model)\n",
    "\n",
    "    return train_losses, train_accs, test_losses, test_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c14feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(model, trainLoader, testLoader, criterion, optimizer, n_epochs, device):\n",
    "#     train_losses = []\n",
    "#     train_accs = []\n",
    "#     test_losses = []\n",
    "#     test_accs = []\n",
    "#     for epoch in range(1, n_epochs + 1):\n",
    "#         model.train()\n",
    "#         train_loss = 0\n",
    "#         train_acc = 0\n",
    "#         for batch in tqdm(trainLoader):\n",
    "#             data, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "#             out = model(data)\n",
    "#             preds = out.argmax(dim=1)\n",
    "#             loss = criterion(out, labels)\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             train_loss += loss.item()\n",
    "#             train_acc += (preds == labels).sum().item()\n",
    "\n",
    "#         train_loss /= len(trainLoader)\n",
    "#         train_acc /= len(trainLoader.dataset)\n",
    "#         train_accs.append(train_acc)\n",
    "#         train_losses.append(train_loss)\n",
    "\n",
    "#         model.eval()\n",
    "#         test_loss = 0\n",
    "#         test_acc = 0\n",
    "#         with torch.no_grad():\n",
    "#             for batch in tqdm(testLoader, disable=True):\n",
    "#                 data, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "#                 out = model(data)\n",
    "#                 loss = criterion(out, labels)\n",
    "#                 preds = out.argmax(dim=1)\n",
    "#                 test_loss += loss.item()\n",
    "#                 test_acc += (preds == labels).sum().item()\n",
    "\n",
    "#         test_loss /= len(testLoader)\n",
    "#         test_acc /= len(testLoader.dataset)\n",
    "#         test_accs.append(test_acc)\n",
    "#         test_losses.append(test_loss)\n",
    "\n",
    "#         print(\n",
    "#             f\"epoch {epoch} | train loss {train_loss:.3f} train acc {train_acc:.2f} | test loss {test_loss:.3f} test acc {test_acc:.2f}\"\n",
    "#         )\n",
    "#     return train_losses, train_accs, test_losses, test_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e090dce",
   "metadata": {},
   "source": [
    "---\n",
    "#### Training parameters - one single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f11b91b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params 2255065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/ml-deploy/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 120 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-3\n",
    "dropout = 0 #0.2\n",
    "batch_size = 512\n",
    "n_epochs = 9\n",
    "num_workers = 120\n",
    "hidden_dim = 512\n",
    "n_filters = 64 # 30\n",
    "n_layers = 2 # 2\n",
    "\n",
    "params = {\"n_filters\": n_filters, \"hidden_dim\": hidden_dim, \"n_layers\": n_layers, \"n_classes\": n_classes, \"dropout_rate\": dropout}\n",
    "model = CNN(**params).to(device)\n",
    "n_params = sum([p.numel() for p in model.parameters()])\n",
    "print(f\"Number of params {n_params}\")\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "trainLoader, testLoader = (\n",
    "    DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers),\n",
    "    DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers),\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ad7d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many epochs to wait after last time validation loss improved.\n",
    "            min_delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.early_stop = False\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss < (self.best_loss - self.min_delta):\n",
    "            # Loss improved! Save the model state and reset counter\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model_state = model.state_dict()\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            # Loss didn't improve enough\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def load_best_weights(self, model):\n",
    "        \"\"\"Restores the model weights from the epoch with the best loss\"\"\"\n",
    "        if self.best_model_state:\n",
    "            model.load_state_dict(self.best_model_state)\n",
    "            print(f\"Restored best model with loss: {self.best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ad96a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 1/9 completed | Train Loss: 1.4900 Acc: 0.638 | Test Loss: 1.3297 Acc: 0.668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 2/9 completed | Train Loss: 1.2102 Acc: 0.698 | Test Loss: 1.2334 Acc: 0.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 3/9 completed | Train Loss: 1.1332 Acc: 0.715 | Test Loss: 1.1821 Acc: 0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 4/9 completed | Train Loss: 1.0119 Acc: 0.745 | Test Loss: 1.0919 Acc: 0.727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 5/9 completed | Train Loss: 0.9879 Acc: 0.751 | Test Loss: 1.0874 Acc: 0.729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 6/9 completed | Train Loss: 0.9755 Acc: 0.754 | Test Loss: 1.0856 Acc: 0.729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 7/9 completed | Train Loss: 0.9571 Acc: 0.758 | Test Loss: 1.0788 Acc: 0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 8/9 completed | Train Loss: 0.9542 Acc: 0.759 | Test Loss: 1.0782 Acc: 0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 9/9 completed | Train Loss: 0.9526 Acc: 0.759 | Test Loss: 1.0779 Acc: 0.731\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_accs, test_losses, test_accs = train(\n",
    "    model, trainLoader, testLoader, criterion, optimizer, n_epochs, device, scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bec883bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"weights/cnn_fullbatch_accuracy.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cee513",
   "metadata": {},
   "source": [
    "---\n",
    "## Random Search - multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb1334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "num_workers = 40\n",
    "\n",
    "trainLoader, testLoader = (\n",
    "    DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers),\n",
    "    DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98235968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_search(search_space,key):\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    best_params = {}\n",
    "    values_to_test = search_space[key]\n",
    "    trials = len(values_to_test)\n",
    "    \n",
    "    print(f\"Starting optimization for key: '{key}' with {trials} values: {values_to_test}\")\n",
    "\n",
    "    for i, val in enumerate(values_to_test):\n",
    "        # 1. Sample random parameters\n",
    "        params = {}\n",
    "        for k, v in search_space.items():\n",
    "            if k == key:\n",
    "                # Force the specific value for the key we are testing\n",
    "                params[k] = val\n",
    "            elif isinstance(v, list):\n",
    "                # If other params are lists, pick one randomly (or you could pick the first)\n",
    "                params[k] = random.choice(v)\n",
    "            else:\n",
    "                # If it's a scalar (single number), just use it\n",
    "                params[k] = v\n",
    "\n",
    "        print(f\"\\n--- Trial {i+1}/{trials} ---\")\n",
    "        print(f\"Testing params: {params}\")\n",
    "                \n",
    "        # 3. Initialize Model with new hidden_dim and dropout\n",
    "        model = CNN(\n",
    "            n_filters=30, \n",
    "            hidden_dim=params['hidden_dim'], \n",
    "            n_layers=2, \n",
    "            n_classes=n_classes,\n",
    "            dropout_rate=params['dropout']\n",
    "        ).to(device)\n",
    "        \n",
    "        n_params = sum([p.numel() for p in model.parameters()])\n",
    "        print(f\"Number of params {n_params}\")\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=params['lr'], weight_decay=params[\"weight_decay\"])\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # 4. Train for fewer epochs (e.g., 5-10) just to check potential\n",
    "        # We don't need to run full 50 epochs to know if parameters are bad\n",
    "        _, _, _, test_accs = train(\n",
    "            model, trainLoader, testLoader, criterion, optimizer, \n",
    "            n_epochs=6, # Short run for speed\n",
    "            device=device,\n",
    "        )\n",
    "        print(f\"Test accuracy for this model: {test_accs[-1]}\")\n",
    "        \n",
    "        # 5. Compare results\n",
    "        final_acc = test_accs[-1]\n",
    "        if final_acc > best_acc:\n",
    "            best_acc = final_acc\n",
    "            best_params = params\n",
    "            print(f\"üöÄ New Best Accuracy: {best_acc:.3f}\")\n",
    "            \n",
    "    print(f\"\\nüèÜ Optimization Finished! Best Params: {best_params} with Acc: {best_acc}\")\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb1ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "        \"lr\": [0.005,0.01],\n",
    "        \"dropout\": 0,\n",
    "        \"hidden_dim\": 256,\n",
    "        \"weight_decay\":1e-3,\n",
    "    }\n",
    "best_hyperparams = multiple_search(search_space, key='lr')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradio-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
